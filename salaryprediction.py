# -*- coding: utf-8 -*-
"""SalaryPrediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SKmJ6TA29HCZhXZW1Y9M2dXVNmQKvnqd
"""



import pandas as pd

df=pd.read_csv('/content/adult 3.csv')

df.head()

df.shape

df.isna().sum()

print(df.gender.value_counts())

df.occupation	.value_counts()

print(df['marital-status'].value_counts())

print(df['education'].value_counts())

print(df['workclass'].value_counts())

df.workclass.replace({'?':'NotListed'},inplace=True)

print(df['workclass'].value_counts())

print(df['relationship'].value_counts())

print(df['native-country'].value_counts)

df.shape

df=df[df['workclass'] != 'Without-pay']
df=df[df['workclass'] != 'Never-worked']

df=df[df['occupation'] != 'Protective-serv']
df=df[df['occupation'] != 'Priv-house-serv']

df=df[df['marital-status'] !='Married-AF-spouse']

df=df[df['education'] !='1st-4th']
df=df[df['education'] !='Preschool']

df.shape

df.drop(columns=['education'],inplace=True)

import matplotlib.pyplot as plt

plt.boxplot(df['age'])
plt.show()

df=df[(df['age']<77) & (df['age']>16)]

plt.boxplot(df['fnlwgt'])
plt.show()

df=df[(df['fnlwgt']<300000)]

plt.boxplot(df['fnlwgt'])

plt.boxplot(df['hours-per-week'])
plt.show()

df=df[(df['hours-per-week']<55) & (df['hours-per-week']>35)]

plt.boxplot(df['hours-per-week'])
plt.show()

from sklearn.preprocessing import LabelEncoder
encoder=LabelEncoder()
df['gender']=encoder.fit_transform(df['gender'])
df['marital-status']=encoder.fit_transform(df['marital-status'])
df['occupation']=encoder.fit_transform(df['occupation'])
df['relationship']=encoder.fit_transform(df['relationship'])
df['race']=encoder.fit_transform(df['race'])
df['native-country']=encoder.fit_transform(df['native-country'])
df['workclass']=encoder.fit_transform(df['workclass'])
df

x=df.drop(columns=['income'])
y=df['income']

from sklearn .preprocessing import StandardScaler
scaler=StandardScaler()
x=scaler.fit_transform(x)

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42 , stratify=y)

from sklearn.neighbors import KNeighborsClassifier
knn=KNeighborsClassifier()
knn.fit(x_train,y_train)

predict=knn.predict(x_test)

from sklearn.metrics import accuracy_score
accuracy_score(y_test,predict)

from sklearn.linear_model import LogisticRegression
lr=LogisticRegression()
lr.fit(x_train,y_train)

predict1=lr.predict(x_test)

from sklearn.metrics import accuracy_score
accuracy_score(y_test,predict1)

from sklearn.neural_network import MLPClassifier
mlp=MLPClassifier(solver='lbfgs',alpha=1e-5,hidden_layer_sizes=(5,2),random_state=1)
mlp.fit(x_train,y_train)

predict2=mlp.predict(x_test)

from sklearn.metrics import accuracy_score
accuracy_score(y_test,predict2)

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import joblib

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

# Define models
models = {
    "LogisticRegression": LogisticRegression(max_iter=1000),
    "RandomForest": RandomForestClassifier(),
    "KNN": KNeighborsClassifier(),
    "SVM": SVC(),
    "GradientBoosting": GradientBoostingClassifier()
}

results = {}

# Train and evaluate
for name, model in models.items():
    model.fit(X_train, y_train)
    preds = model.predict(X_test)
    acc = accuracy_score(y_test, preds)
    results[name] = acc
    print(f"{name}: {acc:.4f}")

# Get best model
best_model_name = max(results, key=results.get)
best_model = models[best_model_name]
print(f"\n✅ Best model: {best_model_name} with accuracy {results[best_model_name]:.4f}")

# Save the best model
joblib.dump(best_model, "best_model.pkl")
print("✅ Saved best model as best_model.pkl")

